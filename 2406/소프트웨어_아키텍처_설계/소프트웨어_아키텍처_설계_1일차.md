# 소프트웨어 아키텍처 설계



5일 -> 3일 간략 버전이므로 이론 보다는 실제 실무에서 자주 사용되는 지식 위주로 진행

1일차 - 기본 이론 + 주로 사용되는 아키텍처 패턴

2일차 - 



- 궁금한거 - lambda vs kappa
- 아키텍처 공부





### 아키텍처가 만들어지는 과정

- 요구사항의 정의 우선순위 산정





- 다양한 설계패턴, 개념 소개





### 아키텍처란

- 모듈, 컴포넌트, 크리스토프 알렉산더
- 고객 + 고객의 고객(실제 사용자) 까지 고려한 설계가 필요
- 렌조 피아노의 사례 - 실제 방문해서 지역, 환경에 맞춘 건축물 설계 + 프로토타입 개발 후 실제 완성



- 아키텍처 기획자로서 중요한 부분 - ceo, coo 등 고객(현업)의 이해를 할 수 있게 의사소통하는 것이 중요



- 모든 요구사항을 받아서 개발할 수 있다면 좋겠지만 현실적 여건에선 불가능. 따라서 각 고객들간 요구사항을 일단 리스트화 한 다음, 거수(고객과 회의를 통해) 가장 중요한 비즈니스 로직 순으로 우선순위를 매겨 부서들 간 충돌을 완충시켜줌



### 아키텍처 드라이버

- 기능적합성, 결함수용성, 실행효율성, 유지보수성, 운영성, 가용성 등 ISO 25010 품질특성 모델

- 시스템 요구사항 분류
  - 기능 요구 사항 - 모니터링 시스템은 서버 트래픽 정보를 제공해야함
  - 비기능 요구사항 - 1분 간격으로 1만대로 부터 모니터링
  - 제약사항 - spring, mysql 으로 진행해야함
- qaw



- 개발 가능한 바운더리를 정하는 작업 (이 이상은 추가비용을 받아야한다, 서로 상호 소통을 통한 조율이 중요)



- 시스템 품질속성 - 최소한 설계 과정에서 논의되고 결정되어야 할 6가지 항목
  - 가용성
  - 변경용이성 
  - 성능 - 웹, 프론트, 백 등 성능 측정을 위한 도구 및 성능 측정법
  - 확장성 - 확장을 위한 알아야 하는 패턴
  - 보안성
  - 시험용이성
  - 사용편의성

- 비즈니스 품질속성 - 개발하고자 하는 프로젝트의 시장, 일정, 비용, 마케팅 등에 연관
  - 시장 적시성
  - 비용과 이익
  - 시스템 생명주기
  - 목표 시장
  - 신규 발매일정
  - 노후 시스템과의 통합



- 품질속성 시나리오 (유저케이스를 uml에 정의하듯)



- 프로젝트 아키텍처 설계 전 사내, 사외에 비슷한 프로젝트 설계 내역이 있는지 찾아보기 (레퍼런스)



- posa 1, posa 2, posa 3
- falut tolerance





## AOSA - 확장가능한 아키텍처



### 핀터레스트 예시

- 고려해야 할 것 - 세계적인 서비스
  - 로컬라이제이션, 타임존 처리 (15분 등), 다국어 처리 (읽는 방향 등)



### 대규모 웹시스템 설계시 핵심 원칙들

- 가용성 - 빠른 장애 복구
- 성능 - 빠른 응답 시간, 낮은 레이턴시 (고객이 실제로 느끼는 것)
- 신뢰성 - 똑같은 요청에 대한 동일한 결과 (신뢰 있는 결과물)
- 확장성 - 최대한 많은 부하를 처리할 수 있도록
- 관리성 - 운용 자체의 편리성 (업데이트, 운용)
- 비용 - 적은 비용



- ROI (비용 대비 이익) - 윗 사람들이 가장 중요시 여기는 부분



### 구글 포토 예시

- 이미지를 업로드, 다운로드 하는 api를 만든다고 가정
- 읽고 쓰기를 분리하지 않는다고 하면 락 발생 가능성을 가짐 (쓰기의 비용이 높고 읽기는 cdn 등을 통해 분산 관리 가능)
- 따라서 읽고 쓰기 구분이 필요
- spof - 이중화가 없이 한개만 있을경우 해당 요소가 장애 발생시 전체 서비스 장애 발생
  - Redundancy 적용 (이중화)
  - 이중화의 경우 각 서버당 최대 비용은 50% (3중화면 66%) 로 관리해야하고 그 이상의 자원이 사용되고 있으면 서버 증설을 고려해야함

- apm (jennifer, whatag, intermax)

- 인프라 모니터링 (Nkia)

- db (exem, shera)

- 자원에 대한 고민이 필수

  

#### 분산 db 아키텍처

- shared nothing - 4코어 컴퓨터 10대 > 40코어 컴퓨터 1대 비용이 싸므로 하나로 통합하는 방법(구현 방안)을 생각하는게 최근 트렌드에 중요, 10대에 부하를 분산시키는 방법
- shared disk - 상대적으로 쉬운편
- shared memory - 비용이 있다면 가장 쉽고 효율

- 파티셔닝 (윈도우 파티셔닝과 거의 동일) - dba가 주로 하는 일(IO확인 후 상황에 맞게 파티셔닝)
  - 버티컬 (수직)
    - db 락이 걸릴까봐 구분 - 자주 사용하는 테이블에서 읽기와 쓰기(업데이트)가 누적되다 보면 락이 발생
    - 따라서 주요 컬럼을 구분하여 (db로 나누든, 테이블을 쪼개든) 관리
  - 호리젠털 (수평) - 스키마는 동일, 범위에 따라서 db를 분리 (a~c - 1번 db, d~g - 2번 db와 같이) 사용공간이 부족해서 쪼개는 경우도 있지만 대부분의 경우 IOPS(IO per sec) 1초에 처리가능한 읽고쓰기 성능 이슈로 인해 쪼개는 경우가 많음 
    - 클라우드에서도 provisioned IOPS 라는 옵션이 존재 (IO가 많으면 최소한의 IO를 보장하기 위해 추가비용을 받음)
    - 분리하는 이유는 IO 부하가 높아지면 큐가 쌓아지다가 더이상 큐를 저장 못함 -> 큐가 날아가버려서 실제 데이터가 저장되지 못하는 이슈 발생할 수 있음 (게임 아이템 먹었는데 서버에 저장 못했다던지..)
    - 비정규화를 하는 이유도 테이블과 IO를 쪼개기 위함
    - exem 홈페이지
    - sharding 이라고 함 (각 db는 shard1, shard2 등으로 부름)
- 최근 db에서의 이슈 - 개인정보 보호로 인한 일정 기간 후 데이터 삭제 -> 코스트를 크게 먹었던 문제 -> 메일을 통해 폐기가 아닌 보관으로 변경 -> 최근에는 TTL - time to live (레디스 등) 기능을 통해 시간 지정후 특정 시간 후 자동 삭제
- TTL 기능을 통해 캐시관리, 락 관리 등도 진행함 (락도 30초 주기로 CS 접근가능한지 확인 후 들어가면 TTL을 통해 데이터 관리)

- 파티셔닝 방법
  - 알고리즘 기반 파티셔닝 (업계에서 별로 사용안됨)
  - Range Based Partitioning (범위를 통한 파티셔닝 - ID, 금액 등 범위) - 주로 사용됨
    - 로컬리티에 대한 장점 + 실제 데이터에 대한 접근이 용이 (범위에 따라 어디에 있을지 추측 가능함)
    - 범위 안에서 다시 쪼갤 경우 해당 작업의 리소스가 크게 듬 (a~d 테이블을 a~b, c~d로 나눌 경우)
  - Key or Hash Based Partitioning - 몽고 db (mongos) 와 같이 우리가 어디에 저장되어있는지는 모르지만 hash(룩업테이블)를 통해 비어있는 shard에 자동으로 분산하여 저장, 관리함 (Auto-shrding)
    - shard가 날아갈 때를 대비해 master 테이블 하단에 백업 테이블 여러 개 생성하여 master는 쓰기, 백업 테이블(레플리카, 슬레이브)은 읽기용으로 사용(몽고의 경우 arbiter) 
    - 혹시나 master 테이블이 죽더라도 다른 테이블로 master로 변경 후 다시 백업 테이블 생성
    - 레플리카셋
    - 단점이라면 우리가 실제 데이터가 어디있는지 직접 접근 불가 + 해시테이블에 대한 부하가 과중됨 (충분한 성능이 뒷받침 되어야함)
  - 로그인 -> 세션 쿠키 발급, 세션 ID로 로그인 인증으로 별도 인증 작업 없이 db 접근 + 세션 쿠키 내 룩업 테이블에 대한 정보 or 분산 테이블에 대한 정보도 같이 저장해두어 과부하를 분산하는 경우도 있음 (게임업계에서 자주 사용)





#### Consistent Hashing

- 전체를 링구조처럼 나눠서 관리하다가 한 서버가 죽었을 때 양 옆의 서버들이 대신하여 데이터를 관리 (각 서버가 부분적으로 받아서 관리)
- 이러한 구조도 결국 주변 서버에 부하를 주는 문제는 존재함
- 따라서 서버의 범위를 가상 노드를 도입해서 더 잘게 쪼개고, 각 노드별로 연관 서버를 나눠서 관리 (촘촘하게)
- Dynamo, Cassandra 등에 사용 - 꼭 실시간 데이터로 안봐도 되는 (느슨한) 페북과 같은 서비스에서 사용
- RDBMS나 전통적인 트랜잭션이 중요할 경우에는 사용하기 조금 어려움
- DB에 따라서 다르게 사용된다
- 돈이 많다면야 각 노드별 백업을 하는게 최선이지만.. 비용 문제가 있음



### 빠르고, 확장 가능, 데이터 접근

- 캐싱 등을 통해 얼마나 빠르게 접근 가능하게 할지 
- 디스크 IO가 실제 장애의 90%, IO를 관리 및 감소 시키는게 최적화하는 방향
- 캐시, 프록시, 인덱스

#### API 에서의 캐시

- 지역성의 원리에 기반 (요청 받은 데이터는 다시 요청 받을 확률이 높다)
- 매우 짧은 시간 동안 유지되는 메모리와 유사
- 캐시 전략을 잘 짜서 최대한 백엔드 (브라우저 캐시는 서버, 데이터 캐시는 db) 에 접근을 줄여주는게 중요
- 캐싱은 로드밸런스와 연관이 깊다
- 로드밸런스(노드스위치)의 경우 IP-Hashing의 경우 한번 접속한 노드로 가능하면 계속 붙여주려고 하므로 캐싱에는 좋지만 부하 분산에 문제가 있음 (소수의 IP만 들어올 경우 특정 서버에만 과중되고 특정서버는 사용안되는 문제 발생) , 라운드로빈의 경우 매번 요청마다 다른 노드로 붙여줌 (캐싱이 어려움)
  - 개선 버전으로 Rount Robin Persistence (Sticky Session) - 처음 접속시엔 라운드로빈으로 부하가 적은 노드로 붙이고, 추가 요청시 처음에 붙였던 노드로 붙이기
- 로드밸런스와 연관성을 줄이기 위한 global cache 두가지 방식
- 전역 캐시 - A type (메인 화면과 같이 특정한 케이스에서만 사용)
  - 모든 노드가 같은 데이터를 봐야할 때 (동일한 메인 페이지, 메인 화면)
  - 짧은 시간 동안 유지되어야 하는 데이터
- 전역 캐시 - B type (레디스와 같은 곳에서 사용하는 것) - 개발자에서 중요하게 고려해야할 부분
  - 레디스와 같이 db 접근전 해당 요청 데이터 이력이 있는지 확인 후 있으면 캐시 서버에서 바로 반환 (db 접근을 안하므로 시간, 비용 절감)
  - 레디스에 대한 많은 공부 및 최적화가 db 최적화에 큰 도움을 줌
- CDN 분산 캐시 (대표적으로 Akamai 등)



- 캐시에 데이터가 없을 때 



### Redis 

- redis - 매우 중요. 캐시 + 자료구조 + 데이터 추정기술까지 제공 (RDBMS의 부하를 줄이기 위한 기능이 많음) - DB 접근을 어떻게든 줄이기 위한 다양한 기능이 많으므로 유용하게 활용해야함
  - 자료구조 -  리더보드 정렬작업시 db 정렬이 아닌, sorted set (zset) 구조를 통해 일정 순위까지 미리 캐시에 저장해두면 매번 db 풀스캔 정렬을 하지 않아도 됨 + 자주 찾는 데이터에 대한 값 여부를 저장해두면 쿼리까지 안들어가도 됨
  - 데이터 추정 기술
- 레디스 재판매 외에는 사용이 가능 
- probabilistic
- 다양한 기술을 사용해서 db 가는 io를 줄여보자 (실제 우리 서비스에도 도입해보면..?)
- KPPG
- bytebytego

#### Redis use case

- 캐시
  - primary(master) write-only - replica(secondary, slave) read-only = 하나의 구조 레플리카셋
  - 캐시 생성 및 TTL 적용
  - lrw 캐시?

- 세션스토어 
- AOF, Snapshot 으로 복구가 용이 (db로도 저장, 파일로도 저장)
- 분산 락 - TTL을 걸어서 시간 종료 후 자동 락(해당하는 영역) 해제 + Pubsub를 통해 클라이언트에 접근하고자 했던 영역의 락이 풀리면 알려줌
- Rate Limiter - API의 부하 한계를 설정하여 한계치 이상의 요청이 올 경우, 레디스에서 반환 (자바에도 서킷브레이커 등으로 존재하긴함)
  - Token Bucket - 요청 마다 토큰 수 제거 - 토큰 수가 0개가 되면 요청 거절 (자바 서킷브레이커와 동일)
  - Leaky Bucket - 갑자기 몰려오는 부하를 처리하는 법 (명절 KTX 예매와 같은 경우) - 깔떼기에 담듯, Bucket에서 실제 서버에는 일정한 양만 처리 가능하도록 흘려보냄
  - fixed window counter - 1초(또는 1분)당 처리할 수 있는 양을 제한, 경계 시점에 몰릴 가능성이 있다
  - slide window counter - 조금 더 유동적으로 요청을 허용하도록 변경하여 제한 (유동적)
- Leader Board - Heavy Hitter (높은 빈도수) 를 관리하거나 이상 데이터 확인할 때 (짧은 시간에 많은 요청이나 데이터 변경 등)

- 확률적 자료구조 (신규 기능) probabilistic data structures
  - 대규모 데이터를 다루는 데 사용되는 데이터 구조와 알고리즘
  - 데이터를 정확하게 저장하는 대신, 근사치를 사용하여 데이터를 압축하고 처리
  - 일정한 오차는 존재하지만, 적은 리소스로 효율적인 구조를 생성 가능





### proxies

- Forward Proxy - pc에서 요청이 나갈 때
- Reverse Proxy - pc에서 요청이 들어올 때 



### Load Balancers

- 외부로 들어오는 요청을 내부 서버에 부하를 분산하기 위해 사용 (여러 서버에 적절히 분산하여 처리 시킴)
- 적절히 분산 = Reverse Proxy
- R.R, Sticky R.R, Weighted R.R, IP/URL hash(특정 url 별로 분산 - 결제는 1번, 로그인은 2번 등)
- Haproxy 샘플 - URL로 구분
- IP (port) 로 분배 - L4 로드 밸런싱
- L7 로드 밸런싱 (어플리케이션-url 로 밸런싱)
- Global Load Balancing - 가장 가까운 dns 및 웹, was서버로 연결하도록 (dns 서버에서 제공을 할 경우)



#### 동기적 요청을 비동기적으로 처리하기 Message queue

- Half-Sync / Half-Async 일부는 동기, 일부는 비동기로 처리

- Message Queues - 실시간 통계, 모니터링 서비스에서 자주 사용

- RabbitMq(안정성, iot연동)

  - 클라이언트와 4handsuake 를 통해 최소 1개의 메세지 큐 보장

- Kafka(빅데이터, 실시간 센서 데이터 등 속도에 장점)

  - 중복 큐가 생기더라도 일단 큐에 넣어줌 (속도)

- 예제

- ```java
  package net.theceres;
  
  import com.rabbitmq.client.Channel;
  import com.rabbitmq.client.Connection;
  import com.rabbitmq.client.ConnectionFactory;
  
  import java.io.IOException;
  import java.util.concurrent.TimeoutException;
  
  public class Send {
      private final static String QUEUE_NAME = "hello";
  
      public static void main(String[] args) {
          // 이 부분을 실제 api로 들어오는 json, 데이터 부분을 받아 큐에 넣도록 바꾸면 됨
          ConnectionFactory factory = new ConnectionFactory();
          factory.setHost("localhost");
          factory.setPort(35672);
          factory.setUsername("uguest");
          factory.setPassword("pguest");
          try (Connection connection = factory.newConnection(); Channel channel = connection.createChannel()) {
              for (int i = 0; i <= 100000; i++) {
                  channel.queueDeclare(QUEUE_NAME, false, false, false, null);
                  String message = "Hello World!" + (int) (Math.random() * 100);
                  channel.basicPublish("", QUEUE_NAME, null, message.getBytes());
                  System.out.println(" [x] Set '" + message + "'");
                  Thread.sleep(10);
              }
          } catch (TimeoutException e) {
              e.printStackTrace();
          } catch (IOException e) {
              e.printStackTrace();
          } catch (InterruptedException e) {
              e.printStackTrace();
          }
      }
  }
  ```

- MQ를 다는 이유 - 한 건 한 건 데이터 io를 처리하게 하면 db 과부하 및 장애 가능성 높음

  - mq에 쌓아서 중간에 일정시간마다 batch (요약 결과물) 를 만들어서 db에 한번에 처리하도록

- RM 여러 대를 사용하여 하나의 거대한 큐 처럼 사용 가능

- RM 장점 - 메모리에 저장 가능 -> 메모리가 부족할 경우 디스크 저장공간 활용하여 저장, 임시적으로 많은 데이터가 들어온다면 MQ 쌓아서 보관하다가 처리 가능할 만큼 꾸준히 처리하도록

- Message Broker - 많은 데이터가 들어와서 소비할 경우 사용 
- Event Broker - 단순 큐 저장이 아닌 특정 이벤트에 따라 구분해서 queue에 쌓음 (특정 이벤트에 따라 데이터 쌓인 부분을 분석하거나 하는 등 중간에 큐 자체만으로도 활용이 필요할 때, 실시간 분석)



## 데이터베이스 톺아보기

- 데이터베이스 분할 (수직, 수평)
- Scale out - 여러 대로 확장 , Scale up - 더 좋은 스펙의 서버로 확장
- Mysql InnoDB 아키텍처 - 직접 db에 쓰기전에 메모리에서 데이터 버퍼를 가지고 변경 상태 저장 -> 나중에 DB에 직접 반영 (1건 1건 직접 반영이 아님)
- Master-Slave Replication - 부하 분산을 위해 master(writer), slave(reader) 로 구분. 다만 유의해야할 점은 각 부분을 ip로 관리한다고 가정하면 마스터가 장애났을 때, 다른 슬레이브가 마스터가 된다면 오픈 소스 등을 활용하여 서버 ip 세팅을 다시 해줘야함 (몽고 db는 자체 기능이 있음) 

Database High Availability



- ProxySQL - DB를 위한 로드 밸런서 (forward?)
  - 레플리카셋이 구성되었을 때, 어플에서는 서버를 지정해서 던질 필요가 없이 crud를 요청하면 해당 요청에 맞춰서 proxySQL 에서 해당하는 서버(읽기 서버, 쓰기 서버)로 적절히 분산해서 던져줌 => 즉 소스나 어플리케이션 단에서 각 서버별 ip를 구분해서 요청할 필요가 없음
  - proxySQL 이 죽을 가능성도 있으니 이중화 하거나 클러스터링을 하거나 해놔야함
  - orchestrator 를 통해 마스터 슬레이브 관계 (마스터가 죽었을 때 교체할 슬레이브 지정하여 마스터로 변경 하는 등) 관리 가능



#### nosql

- 저렴한 비용으로 오라클과 같은 효과를 낼 수 없을까?
- cap 이론 (현재는 잘못되었다고 함) - consistency(항상 동일하게 데이터를 제공할지), availability(같은 데이터는 아니지만 빠르게 응답할지), partition tolerance(노드간 단절이 생길때 어떻게 할지)

- Consistency
  - 신뢰성은 확보하지만 항상 쓰기 완료 후 읽기 동작이 진행되므로 성능적인 비효율은 감수해야함
- Availability
  - 데이터 저장소에 대한 모든 동작(read, write 등)은 항상 성공적으로 반환

- Partition Tolerance (Tolerance to network Partitions)
  - 노드 간에 통신 문제가 생겨 메시지를 주고받지 못하는 상황이라도 동작해야 한다

- 분산 시스템의 경우 3가지 특성 중 2가지만 취해서 사용 가능하다
- CAP가 이론적으로 딱딱하다
- PACELC - 네트워크 단절(P)시 어떻게 대응할 지 까지 함께 고려함
  - P(네트워크 단절)일 경우, A(가용성)과 C(일관성) 중 선택
  - E(else, 정상상황)일 경우, L(빠른 응답우선/일관성은 이후)과 C(일관성) 중 선택
  - PAEC - 대부분의 상황에서 사용함 - 장애 상황시 일단 응답 우선, 평상시는 일관성 우선
    - Consistency 를 강화 할 수 있지만 아주 짧은 시간 내에 동일한 데이터 검증을 필요로 하는 경우는 거의 드물다. 
    - 네이버 패스워드 변경시 (쓰기 후 10초 후에 슬레이브에 적용됨)
  - PAEL - 페이스북 같이 가용성이 중요한 상황에서 (다이나모 db(aws) -> 카산드라(오픈소스) ), 대부분은 C가 지켜지지만 가끔 안지켜지더라도 가용성이 중요하다.
    - C의 레벨을 올릴 수 있지만 굳이 올릴 이유가 잘 없다.
  - PCEC - 트랜잭션의 정보가 매우 민감(중요)할 때 - 은행 돈 예금과 같이 중요한 데이터



- 데이터 저장방식 다양함 ()



### 아키텍처의 다양한 사용 예

#### OLAP, OLTP





#### Lambda 아키텍처

- 과거 데이터는 집계 데이터로 배치로 만들어 저장하고, 실시간 데이터는 바로바로 저장하고
- 배치 데이터와 실시간 데이터를 혼합해서 보여줌
- 중간중간(5분, 10분 등) 집계 데이터로 만들어서 장기간의 데이터를 보관 및 조회 가능하도록
- 주 사용 예시 - 모니터링 서비스, adsence 광고 서비스
- 가장 큰 이슈 - 저 중간 데이터를 어떻게 만들 것인가?
  - 자동으로 만들 수 있다면 베스트 - T.S (Influx - Data Explore 기능 내장) 시계열 데이터 (Aggregation 설정 시 자동 생성),
- 단점
  - 아키텍처가 복잡
  - 과거 데이터가 배치 만들고 나서 들어올 경우 다시 만들어야하는 문제 (과거 데이터가 나중에 들어오는 경우가 많은 서비스)

#### Kappa 

- Kafka (리얼타임)
- 실제 데이터는 RDBMS 등에 저장 하되 각 topic 별로 집계해서 보여주는건 Kafka에 보관
- 디즈니 예시
  - 다양한 주제별로 분류 (연령, 국가, 배우, 장르 등)



#### Geo Spatial 아키텍처

- 위치기반 서비스 아키텍처의 경우는?

##### Uber 사례

- LBS - 공급자-수요자
- 1단계 설계 - 일반적인 로드밸런싱 -> db 과부하
- 2단계 설계 - 도시 id를 기반으로 캐시화 -> 주변 도시의 데이터까지 고려하여 조회가 안됨 (도시의 경계선에 있더라도 해당 도시의 택시만 찾아줌) + 특정 시간대에 대도시에 트래픽이 많이 몰릴 경우 (서울의 퇴근시간 등)
- 3단계 설계 - 드라이버까지 고려하여 서브 샤딩, 인덱스 복사본을 통한 부하 분산
- 4단계 설계 - Geo Hash를 도입하여 부하를 나누기 (Geo hash 6자리) - 각 지역을 자리별로 단위로 쪼개서 통합 관리
  - 지역 경계 문제 해결 (근처 hash 만 찾으면 되니)
  - 다만 특정 지역에 사용 빈도가 많을 때 (사람이 많은 곳) 해당 지역에 대해 좀 더 세밀하게 쪼개서 관리하면 안될까? + 사용 빈도가 적은 지역은 지역 구분을 더 넉넉하게 잡아서 관리한다면?
- 5단계 - 더 좋은 geohash 도입 (사용 빈도에 따라 geohash 단위를 변경하여 적용)
- 6단계 - 동적으로 움직이는 대상을 어떻게? -> redis에 넣어 TTL 적용 시켜 저장 (실제 위치 실시간으로 redis에 저장 후, 약 5초 정도 후에 과거 데이터 삭제 + 현재 데이터 표시해서 실시간 움직임을 표현)
- 쏘카 기술블로그 (gps 부정확한 곳을 개선하기 위해)
- Geo hash는 사각형으로 저장했는데, 실제 지구는 원형이므로 그러한 오차를 보정하기 위한 방법 -> 구글 S2 Library 사용하여 보정
- 돈을 벌기 위한 다양한 서비스 추가 (부정 거래 감지, 여행 시간 예측, 시간별 수요 예측) - Kappa 아키텍처 도입 
  - 시간별 수요 예측을 통해 수요 공급을 분석하고 이에 따라 Dynamic Pricing 도입 (수요가 많을 때 비싼 가격으로 받고, 수요가 적을 때 가격을 낮추고) - 실시간 광고 요금 등
- 추가 참고 아키텍처 (쿠팡 아키텍처)



왜 이런서비스가 도입되었을까?



## MSA + CLOUD 패턴

- 하나의 스타일로 대형 어플리케이션 구성이 어렵기 때문에 분산화 하자
- 왜 쓰지?
  - 비용 이슈 - SCALE OUT 이 비용 적인 측면에서 유리
  - 특정 언어, 플랫폼 장점 극대화
  - 다양한 오픈소스, 상용 제품 출현
- 뿌리 - Microsoft
- 알아둬야 할 핵심 (긴 트랜잭션 처리하기, 트랜잭션 관리, 쿼리, 통신/API 접근, 데이터 집약 성능향상, 확장성)



#### 사가 패턴

- 오랫동안 전해오는 이야기 -> 긴 트랜잭션을 처리하는 패턴
- 내부 일반적인 서비스 (오케스트레이션)
- 외부의 서비스와 연동하는 기술 (크로노그래피)
- Api Mgmt 

#### Database per Service 패턴

- 각 ms의 기능에 맞는 db를 적용해라
- elasticsearch -> opensearch
- GPL, LGPL - 내 소스를 공개하되 프로젝트 만들 때 프로젝트 소스를 공개해야함, 독립된 버전으로 불러만 와서 사용한다 -> 사용 가능하나 불안하므로 사용 하지 않길 권장
- BSD, MIT - 상업적 사용은 문제 없으나 특허권에 대해 문제 소지시 책임지지 않음 (해당 라이브러리 내 특허권을 가진 소스가 존재할 경우 발생할 법적 문제 여지 존재함)
- apache - 특허권 양도 되어있음
- SPL 라이센스



### 데이터 일관성 유지

- Domain Event - 같은 id더라도 판매자, 구매자가 조회할 수 있는 페이지가 차이가 있듯 각 도메인 별로 별도 관리
- Event Sourcing - 이력 관리가 필요한 서비스 (본인 인증이 필요함), 각 이벤트 절차가 잘못되면 다시 시행



#### 트랜잭션 관리

- transactional outbox - sms 발송 서비스 예시. 특정 테이블에 데이터를 넣어두면 스케쥴러에서 데이터를 꺼내서 실제 sms 발송 등 서비스 처리



- 하이퍼 로그



- Competing consumer - 데이터 꺼내가는 쪽 (worker)



- Messaging Dead Letter Queue - 오류로 처리되지 못했던 메시지 내역을 별도의 큐에 보관, 해당 내역 확인 후 수정 작업 진행 (예외 처리)



#### API 접근

- API gateway
- BFF (Backends for Frontends) - 각 프론트엔드에 대응하는 API 제공
  - 같은 이미지 파일이라도 pc에서는 고해상도, 모바일에서는 저해상도로 파일을 리턴하도록
  - webp, prgrquest?





### 데이처 처리 성능 향상 패턴



- Map-Reduce 패턴
  - 대용량 데이터 분산 처리
- Materialized View 패턴
  - JOIN을 계속 걸지 않고, 미리 뷰를 만들어서 사용
- Scatter - Gather





- Sidecar
- Ambassador





## POSA 1

- 크리스토퍼 알렉산더 -> Gang of Four (GOF 디자인 패턴) - 거대한 패턴과 패턴을 이어주는 접착제 (심오한 설계는 어려움) - 간략한 이해정도만 필요
- B, C, S 에 대한 개념만 알아둬도 될 듯
  - B 행위
  - C 생성?
  - S 구조 
- 여러개의 패턴이 뭉쳐서 하나의 거대한 패턴이 만들어짐



### 레이어 패턴

- DSM (dependency structure ) - 레이어 패턴 (엄격하게)
- 역참조 제거가 중요



### 파이프 필터 패턴

- 파이프 - 데이터 삽입, 필터 - 데이터 제거 (7layer )



### 브로커 패턴

- IDL을 통한 데이터 통신? 한쪽 파이선 <-> 자바 간 통신 (apache thrift, google protocol buffer) 
- json 없이 바로 연결

- 안드로이드 바인더 - 각 앱간 통신시 메모리 접근 허용 + 모니터링 가능



### 마스터 슬레이브 패턴



### Client-Dispatcher 패턴

- 클라이언트 요청에 대한 서버가 어떻게 처리할지 (스프링, nodsjs 핵심패턴)
- Reactor/Proactor/Con-Acc



### Publisher-Subscriber

- 기상청 예시 
- 주기적으로 데이터를 받아와하는 서비스의 경우 구독신청(옵저버) -> 데이터 변경시 퍼블리시(push) 제공
- pub-sub



### Event Channel

- pub-sub 에서 발전된 형태
- pub-sub 사이에 이벤트 채널 추가
- 현실적인 경우 - 우선순위까지 매겨서 제어함 (특정 기능별 우선순위 및 로직 처리 + 주기적으로 받기)



### Model-View-Controller

- mvvm, mvp 패턴 등



### PAC 패턴

- 파워포인트
- 다루고자하는 컨텍스트에 따라 UI를 능동적으로 제공



### Command processor

- 명령별로 별도 저장





### Reflection 패턴

- AOP
- 특정 동적 바인딩에 대한 런타임시 해당 서비스에 맞게끔 (jar, dll) 클래스 생성
- 런타임시에 만들기 때문에 성능이 느림



### BCI (byte code instrument)

- 코드가 컴파일 될 때 함수를 만드는 기술 (런타임이 아닌)
- Reflection과 유사하나 컴파일해서 바이트코드로 만드는 시점에 특정 조건에 따라 특정 함수, 특정 기능을 끼워넣는(변조) 기술 - ASM에서 지원해줌
- visitor 패턴을 쓴 사례
- 외부 프레임워크 or 소스코드가 없는 문제 해결때 자주 사용됨 ()